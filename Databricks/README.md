

**–û—Å–Ω–æ–≤—ã Databricks**

–ß—Ç–æ —Ç–∞–∫–æ–µ Databricks –∏ —á–µ–º –æ–Ω –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ Apache Spark?

Databricks ‚Äì —ç—Ç–æ –æ–±–ª–∞—á–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ Apache Spark. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ Spark, Databricks –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç:

–£–ø—Ä–∞–≤–ª—è–µ–º—É—é —Å—Ä–µ–¥—É ‚Äì –Ω–µ –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å Spark-–∫–ª–∞—Å—Ç–µ—Ä—ã.

–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ‚Äì Photon Engine, Z-Ordering, Adaptive Query Execution (AQE).

–ü–æ–¥–¥–µ—Ä–∂–∫—É –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ‚Äì –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MLflow.

Data Lakehouse ‚Äì –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ Data Lake (–≥–∏–±–∫–æ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è) –∏ Data Warehouse (SQL-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞).

------------------------------------------------
**–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Databricks?**

Databricks –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è:
* Workspace ‚Äì –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–¥–æ–º, –Ω–æ—É—Ç–±—É–∫–∞–º–∏ –∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

* Clusters ‚Äì —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ Spark-–∫–ª–∞—Å—Ç–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.

* Databricks SQL ‚Äì –º–æ—â–Ω–∞—è SQL-—Å—Ä–µ–¥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö.

* Jobs & Workflows ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è ETL –∏ ML-–ø–∞–π–ø–ª–∞–π–Ω–æ–≤.

* Unity Catalog ‚Äì —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –∏ –¥–æ—Å—Ç—É–ø–∞–º–∏.

* MLflow ‚Äì –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.

------------------------------------------------
**3. –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Databricks Lakehouse Platform?**
Databricks Lakehouse –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç:

* –ì–∏–±–∫–æ—Å—Ç—å Data Lake (—Ö—Ä–∞–Ω–∏–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ S3/ADLS/Google Cloud Storage).
* –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å Data Warehouse (–∏—Å–ø–æ–ª—å–∑—É–µ–º SQL-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏, Delta Lake).
* –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (MLflow, AutoML).

------------------------------------------------
**4. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Databricks**
–ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Databricks?

Databricks –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö (AWS, Azure, GCP) –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
* Storage Layer ‚Äì —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ S3/ADLS/GCS.
* Compute Layer ‚Äì —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ Spark-–∫–ª–∞—Å—Ç–µ—Ä—ã.
* Control Plane ‚Äì —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏, –¥–æ—Å—Ç—É–ø–∞–º–∏ –∏ –ª–æ–≥–∞–º–∏.
* Databricks Runtime ‚Äì –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Spark.

–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Standard, Premium –∏ Enterprise Edition
* Standard ‚Äì –±–∞–∑–æ–≤—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª, –±–µ–∑ Unity Catalog.
* Premium ‚Äì –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (Role-Based Access Control, Table ACLs).
* Enterprise ‚Äì –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ HIPAA –∏ GDPR.

------------------------------------------------
**–ö–ª–∞—Å—Ç–µ—Ä—ã –≤ Databricks**

–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä –≤ Databricks?

–ü–µ—Ä–µ–π—Ç–∏ –≤ Compute ‚Üí Create Cluster.

–í—ã–±—Ä–∞—Ç—å —Ç–∏–ø:
* Interactive Cluster (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏).
* Job Cluster (–¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á).

![img.png](img.png)

–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤, Databricks Runtime, Auto Scaling).

–ù–∞–∂–∞—Ç—å Create Cluster.

üí° –ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —á–µ—Ä–µ–∑ API

"""

import requests

databricks_url = "https://<databricks-instance>/api/2.0/clusters/create"
token = "your-databricks-token"

payload = {
    "cluster_name": "MyCluster",
    "spark_version": "11.3.x-scala2.12",
    "num_workers": 2,
    "node_type_id": "i3.xlarge",
}

headers = {"Authorization": f"Bearer {token}"}
response = requests.post(databricks_url, json=payload, headers=headers)
print(response.json())
""""
-------------------
**–ß—Ç–æ —Ç–∞–∫–æ–µ Auto Scaling –∏ –∫–∞–∫ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç?**

Auto Scaling –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∏–ª–∏ —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–≥—Ä—É–∑–∫–∏.
üí° –ù–∞–ø—Ä–∏–º–µ—Ä:
–ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ CPU <30% ‚Äì Databricks —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤.
–ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ CPU >80% ‚Äì Databricks –¥–æ–±–∞–≤–ª—è–µ—Ç —É–∑–ª—ã.

-----------
**–ß—Ç–æ —Ç–∞–∫–æ–µ Photon Engine –≤ Databricks?**

Photon ‚Äì —ç—Ç–æ –Ω–æ–≤—ã–π C++-–¥–≤–∏–∂–æ–∫ –≤ Databricks, –∫–æ—Ç–æ—Ä—ã–π —É—Å–∫–æ—Ä—è–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å—ã –¥–æ 8 —Ä–∞–∑ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º Spark.

------
**Databricks Notebooks**

–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å Databricks Notebook?
–ü–µ—Ä–µ–π—Ç–∏ –≤ Workspace ‚Üí Create ‚Üí Notebook.
–í—ã–±—Ä–∞—Ç—å —è–∑—ã–∫ (Python, SQL, Scala, R).
–ù–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ –∏ –Ω–∞–∂–∞—Ç—å Run.
---------
**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç Magic Commands (%sql, %python, %scala, %sh)?**

Magic Commands –ø–æ–∑–≤–æ–ª—è—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —è–∑—ã–∫–æ–≤ –≤ –æ–¥–Ω–æ–º –Ω–æ—É—Ç–±—É–∫–µ

-----------

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã Spark –≤ Databricks**

* **Adaptive Query Execution (AQE) ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã.**

* –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ shuffle partitions (—É–º–µ–Ω—å—à–∞–µ—Ç –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ).
* –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (Joins) ‚Äì Spark –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç Broadcast Join –≤–º–µ—Å—Ç–æ Sort-Merge Join.
* Skew Join Optimization ‚Äì –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–¥–Ω–∞ –∏–∑ —Ç–∞–±–ª–∏—Ü —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞.

* **Broadcast Join ‚Äì —É—Å–∫–æ—Ä—è–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞–ª–µ–Ω—å–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å –±–æ–ª—å—à–æ–π.**

–ö–æ–≥–¥–∞ –æ–¥–Ω–∞ –∏–∑ —Ç–∞–±–ª–∏—Ü –º–∞–ª–µ–Ω—å–∫–∞—è, Spark –∫–æ–ø–∏—Ä—É–µ—Ç –µ–µ –Ω–∞ –≤—Å–µ —É–∑–ª—ã, —á—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç JOIN.

–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Broadcast Join?

* –û–¥–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ < 10 –ú–ë (–º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 100 –ú–ë).
* JOIN –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–∞—Å—Ç–æ, –∏ –¥–∞–Ω–Ω—ã–µ —Ä–µ–¥–∫–æ –º–µ–Ω—è—é—Ç—Å—è.

üìå Spark –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç shuffle –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É, –∞ –ø—Ä–æ—Å—Ç–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç –º–∞–ª–µ–Ω—å–∫—É—é —Ç–∞–±–ª–∏—Ü—É –ø–æ —É–∑–ª–∞–º, —á—Ç–æ —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É –≤ 3-5 —Ä–∞–∑ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö.

* **Z-Ordering ‚Äì —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–ª—é—á–∞–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.**

Z-Ordering ‚Äì —ç—Ç–æ –º–µ—Ç–æ–¥ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Delta Lake, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–∞–Ω–∏—Ä—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤.

üîπ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Z-Ordering?

* –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–º–µ—Å—Ç–µ, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é.
* –£–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∏—Ç–∞–µ–º—ã—Ö —Å—Ç—Ä–æ–∫ –ø—Ä–∏ SQL-–∑–∞–ø—Ä–æ—Å–∞—Ö.
* –†–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ, —á–µ–º –æ–±—ã—á–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (ORDER BY).
* –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫, –ø–æ –∫–æ—Ç–æ—Ä—ã–º —á–∞—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.

> %sql 
> 
> OPTIMIZE sales_table ZORDER BY (customer_id);

------
* **Data Skipping ‚Äì –ø—Ä–æ–ø—É—Å–∫ –Ω–µ–Ω—É–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Delta Lake.**

Data Skipping ‚Äì —ç—Ç–æ –º–µ—Ö–∞–Ω–∏–∑–º, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç Spark –Ω–µ —á–∏—Ç–∞—Ç—å –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–∞—Ö.

üîπ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Data Skipping?

* Delta Lake –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ –∫–∞–∂–¥–æ–º —Ñ–∞–π–ª–µ (–º–∏–Ω–∏–º—É–º, –º–∞–∫—Å–∏–º—É–º –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö).
* –ü—Ä–∏ WHERE Spark –Ω–µ —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.

> SELECT * FROM sales WHERE order_date = '2023-06-01';

–ë–µ–∑ Data Skipping: Spark —á–∏—Ç–∞–µ—Ç –≤—Å—é —Ç–∞–±–ª–∏—Ü—É.

üî• –° Data Skipping: Spark —á–∏—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã.

* **Caching ‚Äì –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ DataFrame –≤ –ø–∞–º—è—Ç–∏.**

–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç–∏, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã.

üîπ –ö–∞–∫–∏–µ —Ç–∏–ø—ã –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –±—ã–≤–∞—é—Ç?

* df.cache() ‚Äì –∫–µ—à–∏—Ä—É–µ—Ç DataFrame –≤ RAM.
* df.persist(StorageLevel.DISK_ONLY) ‚Äì —Ö—Ä–∞–Ω–∏—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–∏—Å–∫–µ, –µ—Å–ª–∏ RAM –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç.
* CACHE TABLE ‚Äì –∫–µ—à–∏—Ä—É–µ—Ç SQL-—Ç–∞–±–ª–∏—Ü—É.

üí° –ü—Ä–∏–º–µ—Ä –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è DataFrame

df = spark.read.parquet("s3://data-lake/sales")

df.cache()

df.count()  # –ü–µ—Ä–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ–π

df.show()  # –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –≤—ã–∑–æ–≤—ã –±—É–¥—É—Ç –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏

* **Auto Scaling ‚Äì –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ.**

* –ï—Å–ª–∏ –Ω–∞–≥—Ä—É–∑–∫–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è, Databricks –¥–æ–±–∞–≤–ª—è–µ—Ç —É–∑–ª—ã.
* –ï—Å–ª–∏ –Ω–∞–≥—Ä—É–∑–∫–∞ —Å–Ω–∏–∂–∞–µ—Ç—Å—è, Databricks —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ —É–∑–ª—ã, —ç–∫–æ–Ω–æ–º—è –¥–µ–Ω—å–≥–∏.

Databricks —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤.

------------

**–ß—Ç–æ —Ç–∞–∫–æ–µ Delta Lake?**

Delta Lake ‚Äì —ç—Ç–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è Apache Spark, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–±–∞–≤–ª—è–µ—Ç:

* ACID-—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö).
* Time Travel (–∏—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö).
* Schema Evolution (–≥–∏–±–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ö–µ–º—ã).
* Efficient Merge & Upsert (–±—ã—Å—Ç—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö).
* Data Versioning (—É–ø—Ä–æ—â–∞–µ—Ç –æ—Ç–∫–∞—Ç –∫ —Å—Ç–∞—Ä—ã–º –≤–µ—Ä—Å–∏—è–º).

–ö–∞–∫ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å? 

df.write.**_format("delta")_**.mode("overwrite").save("/mnt/delta/sales")

------------
**–ß—Ç–æ —Ç–∞–∫–æ–µ Delta Change Data Feed (CDC)?**

Change Data Feed (CDF) ‚Äì —ç—Ç–æ –º–µ—Ö–∞–Ω–∏–∑–º –≤ Delta Lake, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã.

–ß—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–ª–∞—Ç—å CDC?

* –§–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ‚Äì –Ω–µ –Ω—É–∂–Ω–æ —Å—á–∏—Ç—ã–≤–∞—Ç—å –≤—Å—é —Ç–∞–±–ª–∏—Ü—É.

* –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ ETL-–ø–∞–π–ø–ª–∞–π–Ω–∞—Ö.

* –£—Å–∫–æ—Ä—è—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Structured Streaming.

–ö–∞–∫ –≤–∫–ª—é—á–∏—Ç—å CDC –≤ Delta Lake?
–ü–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º CDF –µ–≥–æ –Ω—É–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ:

ALTER TABLE sales ENABLE CHANGE DATA FEED;

–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –ª—é–±—ã–µ INSERT, UPDATE, DELETE —Ñ–∏–∫—Å–∏—Ä—É—é—Ç—Å—è –≤ Change Data Table.

–ï—Å–ª–∏ CDC –≤–∫–ª—é—á–µ–Ω, –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏:

df_changes = spark.read.format("delta") \
    .option("readChangeData", "true") \
    .option("startingVersion", 5) \
    .load("/mnt/delta/sales")

df_changes.show()

‚úÖ –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ø–æ—Å–ª–µ –≤–µ—Ä—Å–∏–∏ 5

-----------------
**Managed / External tables**

–í Databricks –∏ Delta Lake –µ—Å—Ç—å –¥–≤–∞ —Ç–∏–ø–∞ —Ç–∞–±–ª–∏—Ü:
* Managed Table (—É–ø—Ä–∞–≤–ª—è–µ–º–∞—è).
* External Table (–≤–Ω–µ—à–Ω—è—è).

üîπ **Managed Table:**

–î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ Databricks (–Ω–∞ S3, ADLS, GCS).

Databricks —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ö–µ–º–æ–π, —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.

–£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —É–¥–∞–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ.


üîπ **External Table**

–î–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ (S3, ADLS).

Databricks —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.

–£–¥–∞–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã.

------------
**–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Delta Tables?**

üîπ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–∞–µ—Ç —Ç—Ä–∏ —à–∞–≥–∞:

1) **OPTIMIZE ‚Äì —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤**

>_OPTIMIZE sales_

* –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–∞–ª–µ–Ω—å–∫–∏–µ —Ñ–∞–π–ª—ã –≤ –∫—Ä—É–ø–Ω—ã–µ (—É–º–µ–Ω—å—à–∞–µ—Ç I/O).
* –£—Å–∫–æ—Ä—è–µ—Ç SQL-–∑–∞–ø—Ä–æ—Å—ã –∏ —Å—Ç—Ä–∏–º–∏–Ω–≥.


üî• –ü–æ—Å–ª–µ OPTIMIZE —Ñ–∞–π–ª—ã —Å–ª–∏–≤–∞—é—Ç—Å—è, –∏ SQL-–∑–∞–ø—Ä–æ—Å—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ.

2) **ZORDER BY ‚Äì —É—Å–∫–æ—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º**

>_OPTIMIZE sales ZORDER BY (customer_id);_

* –°–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫, —á—Ç–æ–±—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±—ã–ª–∞ –±—ã—Å—Ç—Ä–µ–µ.
* –†–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ, —á–µ–º –æ–±—ã—á–Ω—ã–π ORDER BY.


üî• –ï—Å–ª–∏ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ WHERE customer_id = 123, ZORDER —É—Å–∫–æ—Ä—è–µ—Ç –ø–æ–∏—Å–∫.

3) **VACUUM ‚Äì —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö**

>_VACUUM sales RETAIN 7 HOURS;_

–£–¥–∞–ª–∏—Ç –≤—Å–µ —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–º –±–æ–ª–µ–µ 7 —á–∞—Å–æ–≤.

* –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –º–µ—Å—Ç–æ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.
* –û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ.

–í—ã–≤–æ–¥: OPTIMIZE + ZORDER + VACUUM = —Å—É–ø–µ—Ä-–±—ã—Å—Ç—Ä–∞—è —Ç–∞–±–ª–∏—Ü–∞.

--------

**–ß—Ç–æ —Ç–∞–∫–æ–µ Databricks Workflows –∏ –∫–∞–∫ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á–∏?**

Databricks Workflows ‚Äì —ç—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ Databricks.

–ß—Ç–æ –º–æ–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å?
* –ó–∞–ø—É—Å–∫ ETL-–ø–∞–π–ø–ª–∞–π–Ω–æ–≤
* –í—ã–∑–æ–≤ –Ω–æ—É—Ç–±—É–∫–æ–≤, SQL-–∑–∞–ø—Ä–æ—Å–æ–≤
* –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏
* –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Airflow, Apache Oozie

üí° –ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å Workflow (UI)
1. –ü–µ—Ä–µ–π—Ç–∏ –≤ Workflows ‚Üí Create Workflow.
2. –î–æ–±–∞–≤–∏—Ç—å Jobs (–Ω–æ—É—Ç–±—É–∫, Python-—Å–∫—Ä–∏–ø—Ç, SQL, JAR).
3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ (–µ–∂–µ–¥–Ω–µ–≤–Ω–æ, –µ–∂–µ—á–∞—Å–Ω–æ, –ø–æ —Ç—Ä–∏–≥–≥–µ—Ä—É).
4. –í—ã–±—Ä–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

-------

**–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Batch Processing –∏ Streaming Processing**

![img_1.png](img_1.png)

--------------
–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **Auto Loader (CloudFiles)** –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö?

**Auto Loader (CloudFiles)** ‚Äì —ç—Ç–æ —Å–µ—Ä–≤–∏—Å –≤ Databricks –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ (S3, ADLS, GCS).

–ü–æ—á–µ–º—É Auto Loader –ª—É—á—à–µ?

* –ù–µ –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã ‚Äì Databricks –¥–µ–ª–∞–µ—Ç —ç—Ç–æ —Å–∞–º.
* –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ñ–∞–π–ª–æ–≤.
* –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç JSON, CSV, Avro, Delta –∏ Parquet.

> df = (spark.readStream
      .format("cloudFiles") \
      .option("cloudFiles.format", "csv") \
      .option("cloudFiles.schemaLocation", "/mnt/delta/schema/") \
      .load("s3://my-bucket/raw-data"))

_Auto Loader –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç ingestion, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ streaming ETL-–ø—Ä–æ—Ü–µ—Å—Å–∞—Ö._

--------------
# Streaming –≤ Databricks (Structured Streaming)
Structured Streaming –≤ Databricks ‚Äì —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ Apache Spark, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

üîπ –ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Streaming?
* –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö ‚Äì Kafka, Kinesis, Auto Loader, S3, Delta.
* –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äì –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ.
* –í—ã–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö ‚Äì Delta Lake, Snowflake, Redshift, Kafka.
* Checkpointing ‚Äì –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ç—Ä–∏–º–∞.

üí° –ü—Ä–∏–º–µ—Ä: –ß—Ç–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Kafka
>df_stream = (spark.readStream\
             .format("kafka")\
             .option("kafka.bootstrap.servers", "broker1:9092")\
             .option("subscribe", "transactions")\
             .load())\
> 
>df_parsed = df_stream.selectExpr("CAST(value AS STRING)")


üí° –ü—Ä–∏–º–µ—Ä: –ó–∞–ø–∏—Å—å —Å—Ç—Ä–∏–º–∞ –≤ Delta Lake

>(df_parsed.writeStream\
 .format("delta")\
 .option("checkpointLocation", "/mnt/delta/_checkpoints/")\
 .start("/mnt/delta/transactions"))\
> 

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥?

* –ß–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Kafka.
* –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
* –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ Delta Lake (–≥–∞—Ä–∞–Ω—Ç–∏—è ACID).
* –ò—Å–ø–æ–ª—å–∑—É–µ—Ç checkpointing (–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ç—Ä–∏–º–∞).

-----
**–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Micro-batch Processing –∏ Continuous Processing**

![img_2.png](img_2.png)

üí° –ü—Ä–∏–º–µ—Ä Micro-Batch Processing

>df_stream.writeStream \
    .format("delta") \
    .option("checkpointLocation", "/mnt/delta/_checkpoints/") \
    .trigger(processingTime="10 seconds") \
    .start("/mnt/delta/sales")

–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥.

üí° –ü—Ä–∏–º–µ—Ä Continuous Processing
> df_stream.writeStream \
    .format("console") \
    .trigger(continuous="1 second") \
    .start()

–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ.


‚úÖ Micro-Batch ‚Äì –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

‚úÖ Continuous ‚Äì –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–±–∏—Ä–∂–∞, IoT, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ).

-----
**–ö–∞–∫–∏–µ –µ—Å—Ç—å Trigger Modes?**

Triggers –≤ Structured Streaming —É–ø—Ä–∞–≤–ª—è—é—Ç —Ç–µ–º, –∫–∞–∫ —á–∞—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö.

![img_3.png](img_3.png)


---------
**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç Watermarks –∏ Late Data Handling?**

Watermarking –≤ Structured Streaming –ø–æ–º–æ–≥–∞–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–∞–ø–∞–∑–¥—ã–≤–∞—é—â–∏–µ —Å–æ–±—ã—Ç–∏—è, —É–¥–∞–ª—è—è —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ.

üîπ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç Watermark?
* –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äì –µ—Å–ª–∏ —Å–æ–±—ã—Ç–∏–µ –∑–∞–ø–æ–∑–¥–∞–ª–æ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ N –º–∏–Ω—É—Ç, –æ–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.
* –£–º–µ–Ω—å—à–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ ‚Äì —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Å—Ç–µ–π—Ç–µ.

üí° –ü—Ä–∏–º–µ—Ä Watermarking –≤ PySpark
> df_stream.withWatermark("event_time", "10 minutes") \
    .groupBy("category", F.window("event_time", "5 minutes")) \
    .count()

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥?

* –†–∞–∑–±–∏–≤–∞–µ—Ç –ø–æ—Ç–æ–∫ –Ω–∞ –æ–∫–Ω–∞ –ø–æ 5 –º–∏–Ω—É—Ç.
* –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –æ–ø–æ–∑–¥–∞–ª–∏ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 10 –º–∏–Ω—É—Ç.

üìå –í—ã–≤–æ–¥: Watermark –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏ –∏ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö.

----------
**–ö–∞–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ Structured Streaming?**

![img_4.png](img_4.png)

----------
**–ö–∞–∫ –ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ Delta Lake –≤ —Ä–µ–∂–∏–º–µ Streaming?**

![img_5.png](img_5.png)

-----------

![img_6.png](img_6.png)